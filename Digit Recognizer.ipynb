{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnistData(Dataset):\n",
    "    \n",
    "    def __init__(self, data, transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(degrees = (15,30)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "    ])):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        \n",
    "        # distinguish Test_data and Train_data\n",
    "        if len(data.columns) == test_columns:\n",
    "            self.image = data.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
    "            self.label = None\n",
    "        else:\n",
    "            self.image = data.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
    "            self.label = torch.from_numpy(data.iloc[:,0].values)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.label is not None:\n",
    "            return self.transform(self.image[idx]), self.label[idx]\n",
    "        else:\n",
    "            return self.transform(self.image[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total image pixels:  784\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('/Users/Adamyae/Desktop/Demos/Digit Recognizer/train.csv')\n",
    "test_data = pd.read_csv('/Users/Adamyae/Desktop/Demos/Digit Recognizer/test.csv')\n",
    "\n",
    "test_columns = len(test_data.columns)\n",
    "\n",
    "print(\"total image pixels: \", test_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = mnistData(train_data,transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(degrees = (15,30)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "    ]))\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "test_dataset = mnistData(test_data)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "          \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(64 * 7 * 7, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "          \n",
    "        for m in self.features.children():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "        for m in self.classifier.children():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "                \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Adamyae/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:45: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    exp_lr_scheduler.step()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_idx + 1)% 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
    "                100. * (batch_idx + 1) / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data, target in data_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    loss /= len(data_loader.dataset)\n",
    "        \n",
    "    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "        loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [6400/42000 (15%)]\tLoss: 0.104517\n",
      "Train Epoch: 0 [12800/42000 (30%)]\tLoss: 0.091916\n",
      "Train Epoch: 0 [19200/42000 (46%)]\tLoss: 0.085336\n",
      "Train Epoch: 0 [25600/42000 (61%)]\tLoss: 0.023714\n",
      "Train Epoch: 0 [32000/42000 (76%)]\tLoss: 0.199634\n",
      "Train Epoch: 0 [38400/42000 (91%)]\tLoss: 0.029944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Adamyae/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 0.0269, Accuracy: 41660/42000 (99.190%)\n",
      "\n",
      "Train Epoch: 1 [6400/42000 (15%)]\tLoss: 0.041224\n",
      "Train Epoch: 1 [12800/42000 (30%)]\tLoss: 0.012975\n",
      "Train Epoch: 1 [19200/42000 (46%)]\tLoss: 0.133953\n",
      "Train Epoch: 1 [25600/42000 (61%)]\tLoss: 0.016240\n",
      "Train Epoch: 1 [32000/42000 (76%)]\tLoss: 0.097422\n",
      "Train Epoch: 1 [38400/42000 (91%)]\tLoss: 0.049487\n",
      "\n",
      "Average loss: 0.0273, Accuracy: 41647/42000 (99.160%)\n",
      "\n",
      "Train Epoch: 2 [6400/42000 (15%)]\tLoss: 0.154739\n",
      "Train Epoch: 2 [12800/42000 (30%)]\tLoss: 0.094597\n",
      "Train Epoch: 2 [19200/42000 (46%)]\tLoss: 0.153287\n",
      "Train Epoch: 2 [25600/42000 (61%)]\tLoss: 0.203798\n",
      "Train Epoch: 2 [32000/42000 (76%)]\tLoss: 0.010068\n",
      "Train Epoch: 2 [38400/42000 (91%)]\tLoss: 0.054983\n",
      "\n",
      "Average loss: 0.0250, Accuracy: 41661/42000 (99.193%)\n",
      "\n",
      "Train Epoch: 3 [6400/42000 (15%)]\tLoss: 0.029204\n",
      "Train Epoch: 3 [12800/42000 (30%)]\tLoss: 0.011092\n",
      "Train Epoch: 3 [19200/42000 (46%)]\tLoss: 0.020761\n",
      "Train Epoch: 3 [25600/42000 (61%)]\tLoss: 0.124630\n",
      "Train Epoch: 3 [32000/42000 (76%)]\tLoss: 0.087991\n",
      "Train Epoch: 3 [38400/42000 (91%)]\tLoss: 0.079521\n",
      "\n",
      "Average loss: 0.0214, Accuracy: 41693/42000 (99.269%)\n",
      "\n",
      "Train Epoch: 4 [6400/42000 (15%)]\tLoss: 0.082724\n",
      "Train Epoch: 4 [12800/42000 (30%)]\tLoss: 0.137959\n",
      "Train Epoch: 4 [19200/42000 (46%)]\tLoss: 0.037562\n",
      "Train Epoch: 4 [25600/42000 (61%)]\tLoss: 0.029754\n",
      "Train Epoch: 4 [32000/42000 (76%)]\tLoss: 0.094073\n",
      "Train Epoch: 4 [38400/42000 (91%)]\tLoss: 0.033461\n",
      "\n",
      "Average loss: 0.0173, Accuracy: 41786/42000 (99.490%)\n",
      "\n",
      "Train Epoch: 5 [6400/42000 (15%)]\tLoss: 0.089022\n",
      "Train Epoch: 5 [12800/42000 (30%)]\tLoss: 0.005717\n",
      "Train Epoch: 5 [19200/42000 (46%)]\tLoss: 0.044773\n",
      "Train Epoch: 5 [25600/42000 (61%)]\tLoss: 0.043768\n",
      "Train Epoch: 5 [32000/42000 (76%)]\tLoss: 0.008278\n",
      "Train Epoch: 5 [38400/42000 (91%)]\tLoss: 0.027676\n",
      "\n",
      "Average loss: 0.0199, Accuracy: 41744/42000 (99.390%)\n",
      "\n",
      "Train Epoch: 6 [6400/42000 (15%)]\tLoss: 0.026471\n",
      "Train Epoch: 6 [12800/42000 (30%)]\tLoss: 0.165626\n",
      "Train Epoch: 6 [19200/42000 (46%)]\tLoss: 0.053036\n",
      "Train Epoch: 6 [25600/42000 (61%)]\tLoss: 0.018070\n",
      "Train Epoch: 6 [32000/42000 (76%)]\tLoss: 0.019052\n",
      "Train Epoch: 6 [38400/42000 (91%)]\tLoss: 0.005000\n",
      "\n",
      "Average loss: 0.0189, Accuracy: 41749/42000 (99.402%)\n",
      "\n",
      "Train Epoch: 7 [6400/42000 (15%)]\tLoss: 0.011992\n",
      "Train Epoch: 7 [12800/42000 (30%)]\tLoss: 0.123835\n",
      "Train Epoch: 7 [19200/42000 (46%)]\tLoss: 0.026402\n",
      "Train Epoch: 7 [25600/42000 (61%)]\tLoss: 0.008064\n",
      "Train Epoch: 7 [32000/42000 (76%)]\tLoss: 0.069503\n",
      "Train Epoch: 7 [38400/42000 (91%)]\tLoss: 0.031846\n",
      "\n",
      "Average loss: 0.0191, Accuracy: 41744/42000 (99.390%)\n",
      "\n",
      "Train Epoch: 8 [6400/42000 (15%)]\tLoss: 0.034185\n",
      "Train Epoch: 8 [12800/42000 (30%)]\tLoss: 0.010934\n",
      "Train Epoch: 8 [19200/42000 (46%)]\tLoss: 0.023973\n",
      "Train Epoch: 8 [25600/42000 (61%)]\tLoss: 0.004737\n",
      "Train Epoch: 8 [32000/42000 (76%)]\tLoss: 0.041436\n",
      "Train Epoch: 8 [38400/42000 (91%)]\tLoss: 0.094313\n",
      "\n",
      "Average loss: 0.0151, Accuracy: 41801/42000 (99.526%)\n",
      "\n",
      "Train Epoch: 9 [6400/42000 (15%)]\tLoss: 0.170862\n",
      "Train Epoch: 9 [12800/42000 (30%)]\tLoss: 0.006031\n",
      "Train Epoch: 9 [19200/42000 (46%)]\tLoss: 0.064734\n",
      "Train Epoch: 9 [25600/42000 (61%)]\tLoss: 0.069282\n",
      "Train Epoch: 9 [32000/42000 (76%)]\tLoss: 0.168075\n",
      "Train Epoch: 9 [38400/42000 (91%)]\tLoss: 0.101919\n",
      "\n",
      "Average loss: 0.0145, Accuracy: 41825/42000 (99.583%)\n",
      "\n",
      "Train Epoch: 10 [6400/42000 (15%)]\tLoss: 0.070820\n",
      "Train Epoch: 10 [12800/42000 (30%)]\tLoss: 0.053726\n",
      "Train Epoch: 10 [19200/42000 (46%)]\tLoss: 0.002307\n",
      "Train Epoch: 10 [25600/42000 (61%)]\tLoss: 0.028087\n",
      "Train Epoch: 10 [32000/42000 (76%)]\tLoss: 0.025590\n",
      "Train Epoch: 10 [38400/42000 (91%)]\tLoss: 0.065662\n",
      "\n",
      "Average loss: 0.0135, Accuracy: 41825/42000 (99.583%)\n",
      "\n",
      "Train Epoch: 11 [6400/42000 (15%)]\tLoss: 0.010617\n",
      "Train Epoch: 11 [12800/42000 (30%)]\tLoss: 0.050666\n",
      "Train Epoch: 11 [19200/42000 (46%)]\tLoss: 0.022642\n",
      "Train Epoch: 11 [25600/42000 (61%)]\tLoss: 0.002299\n",
      "Train Epoch: 11 [32000/42000 (76%)]\tLoss: 0.041426\n",
      "Train Epoch: 11 [38400/42000 (91%)]\tLoss: 0.001755\n",
      "\n",
      "Average loss: 0.0111, Accuracy: 41865/42000 (99.679%)\n",
      "\n",
      "Train Epoch: 12 [6400/42000 (15%)]\tLoss: 0.013104\n",
      "Train Epoch: 12 [12800/42000 (30%)]\tLoss: 0.000917\n",
      "Train Epoch: 12 [19200/42000 (46%)]\tLoss: 0.009966\n",
      "Train Epoch: 12 [25600/42000 (61%)]\tLoss: 0.015619\n",
      "Train Epoch: 12 [32000/42000 (76%)]\tLoss: 0.015606\n",
      "Train Epoch: 12 [38400/42000 (91%)]\tLoss: 0.003143\n",
      "\n",
      "Average loss: 0.0114, Accuracy: 41851/42000 (99.645%)\n",
      "\n",
      "Train Epoch: 13 [6400/42000 (15%)]\tLoss: 0.061161\n",
      "Train Epoch: 13 [12800/42000 (30%)]\tLoss: 0.000472\n",
      "Train Epoch: 13 [19200/42000 (46%)]\tLoss: 0.017135\n",
      "Train Epoch: 13 [25600/42000 (61%)]\tLoss: 0.001153\n",
      "Train Epoch: 13 [32000/42000 (76%)]\tLoss: 0.035990\n",
      "Train Epoch: 13 [38400/42000 (91%)]\tLoss: 0.047834\n",
      "\n",
      "Average loss: 0.0127, Accuracy: 41824/42000 (99.581%)\n",
      "\n",
      "Train Epoch: 14 [6400/42000 (15%)]\tLoss: 0.028113\n",
      "Train Epoch: 14 [12800/42000 (30%)]\tLoss: 0.002860\n",
      "Train Epoch: 14 [19200/42000 (46%)]\tLoss: 0.023436\n",
      "Train Epoch: 14 [25600/42000 (61%)]\tLoss: 0.028647\n",
      "Train Epoch: 14 [32000/42000 (76%)]\tLoss: 0.031391\n",
      "Train Epoch: 14 [38400/42000 (91%)]\tLoss: 0.078671\n",
      "\n",
      "Average loss: 0.0093, Accuracy: 41873/42000 (99.698%)\n",
      "\n",
      "Train Epoch: 15 [6400/42000 (15%)]\tLoss: 0.074221\n",
      "Train Epoch: 15 [12800/42000 (30%)]\tLoss: 0.028085\n",
      "Train Epoch: 15 [19200/42000 (46%)]\tLoss: 0.024594\n",
      "Train Epoch: 15 [25600/42000 (61%)]\tLoss: 0.032769\n",
      "Train Epoch: 15 [32000/42000 (76%)]\tLoss: 0.001390\n",
      "Train Epoch: 15 [38400/42000 (91%)]\tLoss: 0.000533\n",
      "\n",
      "Average loss: 0.0117, Accuracy: 41855/42000 (99.655%)\n",
      "\n",
      "Train Epoch: 16 [6400/42000 (15%)]\tLoss: 0.043498\n",
      "Train Epoch: 16 [12800/42000 (30%)]\tLoss: 0.004871\n",
      "Train Epoch: 16 [19200/42000 (46%)]\tLoss: 0.003778\n",
      "Train Epoch: 16 [25600/42000 (61%)]\tLoss: 0.005964\n",
      "Train Epoch: 16 [32000/42000 (76%)]\tLoss: 0.024997\n",
      "Train Epoch: 16 [38400/42000 (91%)]\tLoss: 0.003212\n",
      "\n",
      "Average loss: 0.0094, Accuracy: 41871/42000 (99.693%)\n",
      "\n",
      "Train Epoch: 17 [6400/42000 (15%)]\tLoss: 0.002146\n",
      "Train Epoch: 17 [12800/42000 (30%)]\tLoss: 0.002732\n",
      "Train Epoch: 17 [19200/42000 (46%)]\tLoss: 0.067347\n",
      "Train Epoch: 17 [25600/42000 (61%)]\tLoss: 0.053607\n",
      "Train Epoch: 17 [32000/42000 (76%)]\tLoss: 0.018277\n",
      "Train Epoch: 17 [38400/42000 (91%)]\tLoss: 0.089803\n",
      "\n",
      "Average loss: 0.0076, Accuracy: 41905/42000 (99.774%)\n",
      "\n",
      "Train Epoch: 18 [6400/42000 (15%)]\tLoss: 0.072331\n",
      "Train Epoch: 18 [12800/42000 (30%)]\tLoss: 0.019090\n",
      "Train Epoch: 18 [19200/42000 (46%)]\tLoss: 0.040040\n",
      "Train Epoch: 18 [25600/42000 (61%)]\tLoss: 0.023823\n",
      "Train Epoch: 18 [32000/42000 (76%)]\tLoss: 0.030896\n",
      "Train Epoch: 18 [38400/42000 (91%)]\tLoss: 0.040135\n",
      "\n",
      "Average loss: 0.0086, Accuracy: 41896/42000 (99.752%)\n",
      "\n",
      "Train Epoch: 19 [6400/42000 (15%)]\tLoss: 0.095918\n",
      "Train Epoch: 19 [12800/42000 (30%)]\tLoss: 0.000240\n",
      "Train Epoch: 19 [19200/42000 (46%)]\tLoss: 0.001994\n",
      "Train Epoch: 19 [25600/42000 (61%)]\tLoss: 0.003455\n",
      "Train Epoch: 19 [32000/42000 (76%)]\tLoss: 0.011763\n",
      "Train Epoch: 19 [38400/42000 (91%)]\tLoss: 0.002186\n",
      "\n",
      "Average loss: 0.0069, Accuracy: 41914/42000 (99.795%)\n",
      "\n",
      "Train Epoch: 20 [6400/42000 (15%)]\tLoss: 0.000961\n",
      "Train Epoch: 20 [12800/42000 (30%)]\tLoss: 0.039144\n",
      "Train Epoch: 20 [19200/42000 (46%)]\tLoss: 0.039226\n",
      "Train Epoch: 20 [25600/42000 (61%)]\tLoss: 0.003121\n",
      "Train Epoch: 20 [32000/42000 (76%)]\tLoss: 0.026848\n",
      "Train Epoch: 20 [38400/42000 (91%)]\tLoss: 0.000600\n",
      "\n",
      "Average loss: 0.0079, Accuracy: 41901/42000 (99.764%)\n",
      "\n",
      "Train Epoch: 21 [6400/42000 (15%)]\tLoss: 0.001656\n",
      "Train Epoch: 21 [12800/42000 (30%)]\tLoss: 0.006086\n",
      "Train Epoch: 21 [19200/42000 (46%)]\tLoss: 0.003517\n",
      "Train Epoch: 21 [25600/42000 (61%)]\tLoss: 0.012904\n",
      "Train Epoch: 21 [32000/42000 (76%)]\tLoss: 0.022203\n",
      "Train Epoch: 21 [38400/42000 (91%)]\tLoss: 0.037124\n",
      "\n",
      "Average loss: 0.0066, Accuracy: 41927/42000 (99.826%)\n",
      "\n",
      "Train Epoch: 22 [6400/42000 (15%)]\tLoss: 0.004609\n",
      "Train Epoch: 22 [12800/42000 (30%)]\tLoss: 0.002542\n",
      "Train Epoch: 22 [19200/42000 (46%)]\tLoss: 0.076221\n",
      "Train Epoch: 22 [25600/42000 (61%)]\tLoss: 0.056461\n",
      "Train Epoch: 22 [32000/42000 (76%)]\tLoss: 0.017001\n",
      "Train Epoch: 22 [38400/42000 (91%)]\tLoss: 0.016441\n",
      "\n",
      "Average loss: 0.0108, Accuracy: 41869/42000 (99.688%)\n",
      "\n",
      "Train Epoch: 23 [6400/42000 (15%)]\tLoss: 0.009727\n",
      "Train Epoch: 23 [12800/42000 (30%)]\tLoss: 0.022915\n",
      "Train Epoch: 23 [19200/42000 (46%)]\tLoss: 0.018596\n",
      "Train Epoch: 23 [25600/42000 (61%)]\tLoss: 0.052537\n",
      "Train Epoch: 23 [32000/42000 (76%)]\tLoss: 0.001989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23 [38400/42000 (91%)]\tLoss: 0.003898\n",
      "\n",
      "Average loss: 0.0074, Accuracy: 41893/42000 (99.745%)\n",
      "\n",
      "Train Epoch: 24 [6400/42000 (15%)]\tLoss: 0.002291\n",
      "Train Epoch: 24 [12800/42000 (30%)]\tLoss: 0.024492\n",
      "Train Epoch: 24 [19200/42000 (46%)]\tLoss: 0.000894\n",
      "Train Epoch: 24 [25600/42000 (61%)]\tLoss: 0.001226\n",
      "Train Epoch: 24 [32000/42000 (76%)]\tLoss: 0.001427\n",
      "Train Epoch: 24 [38400/42000 (91%)]\tLoss: 0.003399\n",
      "\n",
      "Average loss: 0.0053, Accuracy: 41928/42000 (99.829%)\n",
      "\n",
      "Train Epoch: 25 [6400/42000 (15%)]\tLoss: 0.005476\n",
      "Train Epoch: 25 [12800/42000 (30%)]\tLoss: 0.028954\n",
      "Train Epoch: 25 [19200/42000 (46%)]\tLoss: 0.000898\n",
      "Train Epoch: 25 [25600/42000 (61%)]\tLoss: 0.005149\n",
      "Train Epoch: 25 [32000/42000 (76%)]\tLoss: 0.047132\n",
      "Train Epoch: 25 [38400/42000 (91%)]\tLoss: 0.001599\n",
      "\n",
      "Average loss: 0.0065, Accuracy: 41916/42000 (99.800%)\n",
      "\n",
      "Train Epoch: 26 [6400/42000 (15%)]\tLoss: 0.007014\n",
      "Train Epoch: 26 [12800/42000 (30%)]\tLoss: 0.005566\n",
      "Train Epoch: 26 [19200/42000 (46%)]\tLoss: 0.012143\n",
      "Train Epoch: 26 [25600/42000 (61%)]\tLoss: 0.073210\n",
      "Train Epoch: 26 [32000/42000 (76%)]\tLoss: 0.013823\n",
      "Train Epoch: 26 [38400/42000 (91%)]\tLoss: 0.095088\n",
      "\n",
      "Average loss: 0.0056, Accuracy: 41923/42000 (99.817%)\n",
      "\n",
      "Train Epoch: 27 [6400/42000 (15%)]\tLoss: 0.029205\n",
      "Train Epoch: 27 [12800/42000 (30%)]\tLoss: 0.011084\n",
      "Train Epoch: 27 [19200/42000 (46%)]\tLoss: 0.005344\n",
      "Train Epoch: 27 [25600/42000 (61%)]\tLoss: 0.015165\n",
      "Train Epoch: 27 [32000/42000 (76%)]\tLoss: 0.023385\n",
      "Train Epoch: 27 [38400/42000 (91%)]\tLoss: 0.004140\n",
      "\n",
      "Average loss: 0.0059, Accuracy: 41923/42000 (99.817%)\n",
      "\n",
      "Train Epoch: 28 [6400/42000 (15%)]\tLoss: 0.012989\n",
      "Train Epoch: 28 [12800/42000 (30%)]\tLoss: 0.052582\n",
      "Train Epoch: 28 [19200/42000 (46%)]\tLoss: 0.000624\n",
      "Train Epoch: 28 [25600/42000 (61%)]\tLoss: 0.000360\n",
      "Train Epoch: 28 [32000/42000 (76%)]\tLoss: 0.001062\n",
      "Train Epoch: 28 [38400/42000 (91%)]\tLoss: 0.035186\n",
      "\n",
      "Average loss: 0.0061, Accuracy: 41918/42000 (99.805%)\n",
      "\n",
      "Train Epoch: 29 [6400/42000 (15%)]\tLoss: 0.026012\n",
      "Train Epoch: 29 [12800/42000 (30%)]\tLoss: 0.015672\n",
      "Train Epoch: 29 [19200/42000 (46%)]\tLoss: 0.000807\n",
      "Train Epoch: 29 [25600/42000 (61%)]\tLoss: 0.003802\n",
      "Train Epoch: 29 [32000/42000 (76%)]\tLoss: 0.006872\n",
      "Train Epoch: 29 [38400/42000 (91%)]\tLoss: 0.009825\n",
      "\n",
      "Average loss: 0.0045, Accuracy: 41942/42000 (99.862%)\n",
      "\n",
      "Train Epoch: 30 [6400/42000 (15%)]\tLoss: 0.029722\n",
      "Train Epoch: 30 [12800/42000 (30%)]\tLoss: 0.005636\n",
      "Train Epoch: 30 [19200/42000 (46%)]\tLoss: 0.000677\n",
      "Train Epoch: 30 [25600/42000 (61%)]\tLoss: 0.002138\n",
      "Train Epoch: 30 [32000/42000 (76%)]\tLoss: 0.000903\n",
      "Train Epoch: 30 [38400/42000 (91%)]\tLoss: 0.002240\n",
      "\n",
      "Average loss: 0.0045, Accuracy: 41947/42000 (99.874%)\n",
      "\n",
      "Train Epoch: 31 [6400/42000 (15%)]\tLoss: 0.022940\n",
      "Train Epoch: 31 [12800/42000 (30%)]\tLoss: 0.003373\n",
      "Train Epoch: 31 [19200/42000 (46%)]\tLoss: 0.001838\n",
      "Train Epoch: 31 [25600/42000 (61%)]\tLoss: 0.000210\n",
      "Train Epoch: 31 [32000/42000 (76%)]\tLoss: 0.008174\n",
      "Train Epoch: 31 [38400/42000 (91%)]\tLoss: 0.007932\n",
      "\n",
      "Average loss: 0.0048, Accuracy: 41943/42000 (99.864%)\n",
      "\n",
      "Train Epoch: 32 [6400/42000 (15%)]\tLoss: 0.002939\n",
      "Train Epoch: 32 [12800/42000 (30%)]\tLoss: 0.026982\n",
      "Train Epoch: 32 [19200/42000 (46%)]\tLoss: 0.000451\n",
      "Train Epoch: 32 [25600/42000 (61%)]\tLoss: 0.007449\n",
      "Train Epoch: 32 [32000/42000 (76%)]\tLoss: 0.093195\n",
      "Train Epoch: 32 [38400/42000 (91%)]\tLoss: 0.003886\n",
      "\n",
      "Average loss: 0.0057, Accuracy: 41920/42000 (99.810%)\n",
      "\n",
      "Train Epoch: 33 [6400/42000 (15%)]\tLoss: 0.012102\n",
      "Train Epoch: 33 [12800/42000 (30%)]\tLoss: 0.001436\n",
      "Train Epoch: 33 [19200/42000 (46%)]\tLoss: 0.014379\n",
      "Train Epoch: 33 [25600/42000 (61%)]\tLoss: 0.014522\n",
      "Train Epoch: 33 [32000/42000 (76%)]\tLoss: 0.001605\n",
      "Train Epoch: 33 [38400/42000 (91%)]\tLoss: 0.029791\n",
      "\n",
      "Average loss: 0.0053, Accuracy: 41927/42000 (99.826%)\n",
      "\n",
      "Train Epoch: 34 [6400/42000 (15%)]\tLoss: 0.002023\n",
      "Train Epoch: 34 [12800/42000 (30%)]\tLoss: 0.000462\n",
      "Train Epoch: 34 [19200/42000 (46%)]\tLoss: 0.002791\n",
      "Train Epoch: 34 [25600/42000 (61%)]\tLoss: 0.017664\n",
      "Train Epoch: 34 [32000/42000 (76%)]\tLoss: 0.001331\n",
      "Train Epoch: 34 [38400/42000 (91%)]\tLoss: 0.024727\n",
      "\n",
      "Average loss: 0.0048, Accuracy: 41943/42000 (99.864%)\n",
      "\n",
      "Train Epoch: 35 [6400/42000 (15%)]\tLoss: 0.008758\n",
      "Train Epoch: 35 [12800/42000 (30%)]\tLoss: 0.000972\n",
      "Train Epoch: 35 [19200/42000 (46%)]\tLoss: 0.008216\n",
      "Train Epoch: 35 [25600/42000 (61%)]\tLoss: 0.000167\n",
      "Train Epoch: 35 [32000/42000 (76%)]\tLoss: 0.004519\n",
      "Train Epoch: 35 [38400/42000 (91%)]\tLoss: 0.024514\n",
      "\n",
      "Average loss: 0.0036, Accuracy: 41951/42000 (99.883%)\n",
      "\n",
      "Train Epoch: 36 [6400/42000 (15%)]\tLoss: 0.018408\n",
      "Train Epoch: 36 [12800/42000 (30%)]\tLoss: 0.027003\n",
      "Train Epoch: 36 [19200/42000 (46%)]\tLoss: 0.003174\n",
      "Train Epoch: 36 [25600/42000 (61%)]\tLoss: 0.004029\n",
      "Train Epoch: 36 [32000/42000 (76%)]\tLoss: 0.022191\n",
      "Train Epoch: 36 [38400/42000 (91%)]\tLoss: 0.004838\n",
      "\n",
      "Average loss: 0.0049, Accuracy: 41943/42000 (99.864%)\n",
      "\n",
      "Train Epoch: 37 [6400/42000 (15%)]\tLoss: 0.003229\n",
      "Train Epoch: 37 [12800/42000 (30%)]\tLoss: 0.003450\n",
      "Train Epoch: 37 [19200/42000 (46%)]\tLoss: 0.011679\n",
      "Train Epoch: 37 [25600/42000 (61%)]\tLoss: 0.074055\n",
      "Train Epoch: 37 [32000/42000 (76%)]\tLoss: 0.016302\n",
      "Train Epoch: 37 [38400/42000 (91%)]\tLoss: 0.068893\n",
      "\n",
      "Average loss: 0.0044, Accuracy: 41940/42000 (99.857%)\n",
      "\n",
      "Train Epoch: 38 [6400/42000 (15%)]\tLoss: 0.003871\n",
      "Train Epoch: 38 [12800/42000 (30%)]\tLoss: 0.009156\n",
      "Train Epoch: 38 [19200/42000 (46%)]\tLoss: 0.001566\n",
      "Train Epoch: 38 [25600/42000 (61%)]\tLoss: 0.006915\n",
      "Train Epoch: 38 [32000/42000 (76%)]\tLoss: 0.054711\n",
      "Train Epoch: 38 [38400/42000 (91%)]\tLoss: 0.000173\n",
      "\n",
      "Average loss: 0.0040, Accuracy: 41947/42000 (99.874%)\n",
      "\n",
      "Train Epoch: 39 [6400/42000 (15%)]\tLoss: 0.006016\n",
      "Train Epoch: 39 [12800/42000 (30%)]\tLoss: 0.000825\n",
      "Train Epoch: 39 [19200/42000 (46%)]\tLoss: 0.019612\n",
      "Train Epoch: 39 [25600/42000 (61%)]\tLoss: 0.001296\n",
      "Train Epoch: 39 [32000/42000 (76%)]\tLoss: 0.007500\n",
      "Train Epoch: 39 [38400/42000 (91%)]\tLoss: 0.002750\n",
      "\n",
      "Average loss: 0.0035, Accuracy: 41960/42000 (99.905%)\n",
      "\n",
      "Train Epoch: 40 [6400/42000 (15%)]\tLoss: 0.000617\n",
      "Train Epoch: 40 [12800/42000 (30%)]\tLoss: 0.000668\n",
      "Train Epoch: 40 [19200/42000 (46%)]\tLoss: 0.094974\n",
      "Train Epoch: 40 [25600/42000 (61%)]\tLoss: 0.033266\n",
      "Train Epoch: 40 [32000/42000 (76%)]\tLoss: 0.015495\n",
      "Train Epoch: 40 [38400/42000 (91%)]\tLoss: 0.008902\n",
      "\n",
      "Average loss: 0.0034, Accuracy: 41959/42000 (99.902%)\n",
      "\n",
      "Train Epoch: 41 [6400/42000 (15%)]\tLoss: 0.011132\n",
      "Train Epoch: 41 [12800/42000 (30%)]\tLoss: 0.000044\n",
      "Train Epoch: 41 [19200/42000 (46%)]\tLoss: 0.006407\n",
      "Train Epoch: 41 [25600/42000 (61%)]\tLoss: 0.005089\n",
      "Train Epoch: 41 [32000/42000 (76%)]\tLoss: 0.000679\n",
      "Train Epoch: 41 [38400/42000 (91%)]\tLoss: 0.062149\n",
      "\n",
      "Average loss: 0.0035, Accuracy: 41958/42000 (99.900%)\n",
      "\n",
      "Train Epoch: 42 [6400/42000 (15%)]\tLoss: 0.037328\n",
      "Train Epoch: 42 [12800/42000 (30%)]\tLoss: 0.083699\n",
      "Train Epoch: 42 [19200/42000 (46%)]\tLoss: 0.000736\n",
      "Train Epoch: 42 [25600/42000 (61%)]\tLoss: 0.000965\n",
      "Train Epoch: 42 [32000/42000 (76%)]\tLoss: 0.001454\n",
      "Train Epoch: 42 [38400/42000 (91%)]\tLoss: 0.000227\n",
      "\n",
      "Average loss: 0.0036, Accuracy: 41950/42000 (99.881%)\n",
      "\n",
      "Train Epoch: 43 [6400/42000 (15%)]\tLoss: 0.004825\n",
      "Train Epoch: 43 [12800/42000 (30%)]\tLoss: 0.000946\n",
      "Train Epoch: 43 [19200/42000 (46%)]\tLoss: 0.087191\n",
      "Train Epoch: 43 [25600/42000 (61%)]\tLoss: 0.010045\n",
      "Train Epoch: 43 [32000/42000 (76%)]\tLoss: 0.003348\n",
      "Train Epoch: 43 [38400/42000 (91%)]\tLoss: 0.000547\n",
      "\n",
      "Average loss: 0.0039, Accuracy: 41951/42000 (99.883%)\n",
      "\n",
      "Train Epoch: 44 [6400/42000 (15%)]\tLoss: 0.000312\n",
      "Train Epoch: 44 [12800/42000 (30%)]\tLoss: 0.001424\n",
      "Train Epoch: 44 [19200/42000 (46%)]\tLoss: 0.035054\n",
      "Train Epoch: 44 [25600/42000 (61%)]\tLoss: 0.002156\n",
      "Train Epoch: 44 [32000/42000 (76%)]\tLoss: 0.002872\n",
      "Train Epoch: 44 [38400/42000 (91%)]\tLoss: 0.004716\n",
      "\n",
      "Average loss: 0.0038, Accuracy: 41955/42000 (99.893%)\n",
      "\n",
      "Train Epoch: 45 [6400/42000 (15%)]\tLoss: 0.001844\n",
      "Train Epoch: 45 [12800/42000 (30%)]\tLoss: 0.006802\n",
      "Train Epoch: 45 [19200/42000 (46%)]\tLoss: 0.068060\n",
      "Train Epoch: 45 [25600/42000 (61%)]\tLoss: 0.001827\n",
      "Train Epoch: 45 [32000/42000 (76%)]\tLoss: 0.002802\n",
      "Train Epoch: 45 [38400/42000 (91%)]\tLoss: 0.087442\n",
      "\n",
      "Average loss: 0.0040, Accuracy: 41956/42000 (99.895%)\n",
      "\n",
      "Train Epoch: 46 [6400/42000 (15%)]\tLoss: 0.040520\n",
      "Train Epoch: 46 [12800/42000 (30%)]\tLoss: 0.011411\n",
      "Train Epoch: 46 [19200/42000 (46%)]\tLoss: 0.036263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 46 [25600/42000 (61%)]\tLoss: 0.005715\n",
      "Train Epoch: 46 [32000/42000 (76%)]\tLoss: 0.055611\n",
      "Train Epoch: 46 [38400/42000 (91%)]\tLoss: 0.000304\n",
      "\n",
      "Average loss: 0.0042, Accuracy: 41943/42000 (99.864%)\n",
      "\n",
      "Train Epoch: 47 [6400/42000 (15%)]\tLoss: 0.000220\n",
      "Train Epoch: 47 [12800/42000 (30%)]\tLoss: 0.001703\n",
      "Train Epoch: 47 [19200/42000 (46%)]\tLoss: 0.008906\n",
      "Train Epoch: 47 [25600/42000 (61%)]\tLoss: 0.023150\n",
      "Train Epoch: 47 [32000/42000 (76%)]\tLoss: 0.011560\n",
      "Train Epoch: 47 [38400/42000 (91%)]\tLoss: 0.001029\n",
      "\n",
      "Average loss: 0.0033, Accuracy: 41960/42000 (99.905%)\n",
      "\n",
      "Train Epoch: 48 [6400/42000 (15%)]\tLoss: 0.005036\n",
      "Train Epoch: 48 [12800/42000 (30%)]\tLoss: 0.000819\n",
      "Train Epoch: 48 [19200/42000 (46%)]\tLoss: 0.004230\n",
      "Train Epoch: 48 [25600/42000 (61%)]\tLoss: 0.006106\n",
      "Train Epoch: 48 [32000/42000 (76%)]\tLoss: 0.003668\n",
      "Train Epoch: 48 [38400/42000 (91%)]\tLoss: 0.007553\n",
      "\n",
      "Average loss: 0.0032, Accuracy: 41964/42000 (99.914%)\n",
      "\n",
      "Train Epoch: 49 [6400/42000 (15%)]\tLoss: 0.001782\n",
      "Train Epoch: 49 [12800/42000 (30%)]\tLoss: 0.000063\n",
      "Train Epoch: 49 [19200/42000 (46%)]\tLoss: 0.000401\n",
      "Train Epoch: 49 [25600/42000 (61%)]\tLoss: 0.000533\n",
      "Train Epoch: 49 [32000/42000 (76%)]\tLoss: 0.001915\n",
      "Train Epoch: 49 [38400/42000 (91%)]\tLoss: 0.004232\n",
      "\n",
      "Average loss: 0.0034, Accuracy: 41951/42000 (99.883%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch)\n",
    "    evaluate(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediciton(data_loader):\n",
    "    model.eval()\n",
    "    test_pred = torch.LongTensor()\n",
    "    \n",
    "    for i, data in enumerate(data_loader):\n",
    "        data = Variable(data, volatile=True)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            \n",
    "        output = model(data)\n",
    "        \n",
    "        pred = output.cpu().data.max(1, keepdim=True)[1]\n",
    "        test_pred = torch.cat((test_pred, pred), dim=0)\n",
    "        \n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Adamyae/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_pred = prediciton(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(np.c_[np.arange(1, len(test_dataset)+1)[:,None], test_pred.numpy()], \n",
    "                      columns=['ImageId', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      0\n",
       "4        5      3"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
